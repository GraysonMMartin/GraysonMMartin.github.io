<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Semantic Segmentation of Aerial Photographs | Grayson M. Martin </title> <meta name="author" content="Grayson M. Martin"> <meta name="description" content="Per-pixel land use classification of sattelite imagery of Mumbai"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://graysonmmartin.github.io/projects/cs2831_project/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Grayson</span> M. Martin </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Semantic Segmentation of Aerial Photographs</h1> <p class="post-description">Per-pixel land use classification of sattelite imagery of Mumbai</p> </header> <article> <h2 id="abstract">Abstract</h2> <p>Semantic segmentation of aerial imagery is a critical tool for applications such as environmental monitoring, urban planning, and disaster assessment. In this project, I employed the U-Net architecture attempting a variety of enhancements to improve segmentation accuracy on a set of satellite images of Mumbai. Seven models were trained and evaluated, each integrating specific changes to the base model in loss function, encoder depth, dropout regularization, and addition of attention mechanisms. Metrics including IoU, Dice, Precision, and Recall were used to assess model performance across six classes: vegetation, built-up areas, informal settlements, impervious surfaces, barren land, and water. A small “unclassified” class is also considered.</p> <h2 id="introduction">Introduction</h2> <p>Aerial photography has a wide variety of uses, including geology, archaeology, disaster assessment, and environmental monitoring <a class="citation" href="#NASM_AerialPhotography">(National Air and Space Museum, 2023)</a>. The technology improved and became more widely utilized for military purposes starting in World War I, and has since gone on to be used for tasks such as identifying different vegetation types, detecting diseased and damaged vegetation, and counting how many missiles, planes, and other military hardware adversaries have and where it is located <a class="citation" href="#Baumann_RemoteSensingHistory">(Baumann, 2014)</a>. Semantic segmentation, or pixel-wise classification, is useful in this context. Creating a mask that classifies all regions of an aerial image allows for monitoring of environmental conditions, foreign objects, and changing conditions over time. While this project explores semantic segmentation of aerial images, the technology is useful for a broad number of tasks in biology, robotics, agriculture, sports analysis, and more.</p> <h3 id="semantic-segmentation-performance-metrics">Semantic Segmentation Performance Metrics</h3> <p>Performance metrics for semantic segmentation can be thought of in terms of true positive (TP), false positive (FP), true negative (TN), and false negative (FN) classifications for each pixel.</p> <p>The most common performance metric for semantic segmentation is the Jaccard Score, also known as <em>Intersection over Union (IoU)</em>.</p> \[\mathrm{IoU} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP} + \mathrm{FN}}\] <p>Another frequently used metric for semantic segmentation is the Dice Score, also known as the <em>F1 Score</em>. This metric is formulated from two related metrics, <em>Precision</em> and <em>Recall</em>.</p> \[\mathrm{Precision} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}, \quad \mathrm{Recall} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}\] \[\mathrm{F1} = 2 \times \frac{\mathrm{Precision} \times \mathrm{Recall}}{\mathrm{Precision} + \mathrm{Recall}}\] <h3 id="transposed-convolution">Transposed Convolution</h3> <p>Transposed convolution, also known as <em>upconvolution</em>, is a method of upsampling similar to downsampling with convolution. Between each input pixel, zeros are inserted to increase the size of the feature map before convolution with the kernel. An example of transposed convolution is given below:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/didl_transposed_convolution-480.webp 480w,/assets/img/didl_transposed_convolution-800.webp 800w,/assets/img/didl_transposed_convolution-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/didl_transposed_convolution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="An Example Upconvolution with a 2×2 Input, 2×2 Kernel, and Stride of 1" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> An Example Upconvolution with a 2×2 Input, 2×2 Kernel, and Stride of 1 <a class="citation" href="#zhang2023dive">(Zhang et al., 2023)</a> </div> <h2 id="dataset-description">Dataset Description</h2> <p>The dataset explored in this project is the Manually Annotated High Resolution Satellite Image Dataset of Mumbai for Semantic Segmentation (missing reference). The dataset was created from high-resolution, true-color satellite imagery of Pleiades-1A acquired on March 15, 2017 over Mumbai. There are six classifications: vegetation, built-up areas, informal settlements, impervious surfaces (roads, streets, parking lots, etc.), barren land, water, and a small number of unclassified pixels. The exact pixel distribution for the training set is given in Table 1.</p> <table> <thead> <tr> <th>Class</th> <th style="text-align: right">Informal Settlements</th> <th style="text-align: right">Built-Up</th> <th style="text-align: right">Impervious Surfaces</th> <th style="text-align: right">Vegetation</th> <th style="text-align: right">Barren</th> <th style="text-align: right">Water</th> <th style="text-align: right">Unclassified</th> </tr> </thead> <tbody> <tr> <td><strong># pixels</strong></td> <td style="text-align: right">12,921,604</td> <td style="text-align: right">11,358,632</td> <td style="text-align: right">13,436,578</td> <td style="text-align: right">22,423,411</td> <td style="text-align: right">18,735,038</td> <td style="text-align: right">37,789,523</td> <td style="text-align: right">120,366</td> </tr> </tbody> </table> <p><em>Table 1: Training Patch Pixel Distribution</em></p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Dabra_class_balance-480.webp 480w,/assets/img/Dabra_class_balance-800.webp 800w,/assets/img/Dabra_class_balance-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Dabra_class_balance.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Distribution of Labels Across Patches" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Distribution of Labels Across Patches <a class="citation" href="#Dabra2023">(Dabra &amp; Kumar, 2023)</a> </div> <h2 id="methods">Methods</h2> <h3 id="u-net-architecture">U-Net Architecture</h3> <p>Ronneberger, Fischer, and Brox proposed the first U-Net architecture to segment cells in microscopic images <a class="citation" href="#ronneberger2015unetconvolutionalnetworksbiomedical">(Ronneberger et al., 2015)</a>. The symmetric model consists of a contracting encoder and an expanding decoder with skip connections. In the encoder, each level applies a 3×3 convolution with ReLU activation followed by 2×2 max pooling to reduce spatial dimensions by half. The decoder performs a series of 2×2 upconvolutions to double the spatial dimensions and uses skip connections to preserve spatial information. The final 1×1 convolution reduces the number of channels to the number of classes.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Ronneberger_architecture-480.webp 480w,/assets/img/Ronneberger_architecture-800.webp 800w,/assets/img/Ronneberger_architecture-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Ronneberger_architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="The Original U-Net Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The Original U-Net Architecture <a class="citation" href="#ronneberger2015unetconvolutionalnetworksbiomedical">(Ronneberger et al., 2015)</a> </div> <h3 id="loss-functions">Loss Functions</h3> <h4 id="cross-entropy">Cross-Entropy</h4> \[\mathcal{L}_{ce} = -\sum_{(x,y)} y(x,y)\,\log p(x,y)\] <h4 id="weighted-cross-entropy">Weighted Cross-Entropy</h4> \[\mathcal{L}_{wce} = -\sum_{(x,y)} w(x,y)\;y(x,y)\,\log p(x,y)\] <h4 id="focal-loss">Focal Loss</h4> \[\mathcal{L}_{wfl} = -\sum_{(x,y)}\sum_{c=1}^K w_c\,(1 - p_c(x,y))^\gamma\,y_c(x,y)\,\log p_c(x,y)\] <h3 id="data-augmentation">Data Augmentation</h3> <p>The 120×120 patches are upsampled to 128×128 to be compatible with the five downsampling stages (128 is a multiple of 32). At the start of each epoch, patches and masks are randomly rotated by 0°, 90°, 180°, or 270° to add rotational invariance and prevent overfitting.</p> <h3 id="model-selection">Model Selection</h3> <p>Pre-trained models from the Segmentation Models PyTorch library <a class="citation" href="#Iakubovskii:2019">(Iakubovskii, 2019)</a> were used. EfficientNet-B0 <a class="citation" href="#tan2020efficientnetrethinkingmodelscaling">(Tan &amp; Le, 2020)</a> pre-trained on ImageNet (missing reference) was chosen as the encoder for its small size (4M parameters), reducing overfitting and accommodating limited compute resources.</p> <h3 id="optimizer--scheduler">Optimizer &amp; Scheduler</h3> <p>The Adam optimizer was used with an initial learning rate of 1×10⁻⁴ <a class="citation" href="#Dabra2023">(Dabra &amp; Kumar, 2023)</a>. A LambdaLR scheduler decayed the learning rate by a factor of 0.1 every 40 epochs:</p> \[\lambda(\text{epoch}) = 0.1^{\frac{\text{epoch}}{40}}\] <h3 id="early-stopping">Early Stopping</h3> <p>Training was halted if the validation loss did not improve for five consecutive epochs.</p> <h2 id="results">Results</h2> <h3 id="model-1">Model 1</h3> <p>The initial model follows the Methods exactly and serves as a baseline.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_1_training-480.webp 480w,/assets/img/model_1_training-800.webp 800w,/assets/img/model_1_training-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_1_training.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 1 Training" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 1 Training </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_1_prediction_grid-480.webp 480w,/assets/img/model_1_prediction_grid-800.webp 800w,/assets/img/model_1_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_1_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 1 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 1 Predictions </div> <h3 id="model-2">Model 2</h3> <p>This model introduces Dice loss alongside cross-entropy to better address class imbalance by directly optimizing overlap between prediction and ground truth.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_2_prediction_grid-480.webp 480w,/assets/img/model_2_prediction_grid-800.webp 800w,/assets/img/model_2_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_2_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 2 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 2 Predictions </div> <h3 id="model-3">Model 3</h3> <p>Class-weighted cross-entropy is combined with Dice loss. Weights were computed as the inverse class frequency and normalized; the unclassified class was scaled down by 0.001 before normalization.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_3_prediction_grid-480.webp 480w,/assets/img/model_3_prediction_grid-800.webp 800w,/assets/img/model_3_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_3_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 3 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 3 Predictions </div> <h3 id="model-4">Model 4</h3> <p>A shallower U-Net (encoder depth 4, decoder channels [256,128,64,32]) reduces compute overhead while maintaining performance.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_4_prediction_grid-480.webp 480w,/assets/img/model_4_prediction_grid-800.webp 800w,/assets/img/model_4_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_4_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 4 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 4 Predictions </div> <h3 id="model-5">Model 5</h3> <p>Dropout (p=0.2) was added in the decoder to improve generalization by reducing overfitting.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_5_prediction_grid-480.webp 480w,/assets/img/model_5_prediction_grid-800.webp 800w,/assets/img/model_5_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_5_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 5 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 5 Predictions </div> <h3 id="model-6">Model 6</h3> <p>SCSE attention blocks were incorporated in the decoder to recalibrate feature channels and focus on important regions <a class="citation" href="#roy2018recalibratingfullyconvolutionalnetworks">(Roy et al., 2018)</a>.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_6_prediction_grid-480.webp 480w,/assets/img/model_6_prediction_grid-800.webp 800w,/assets/img/model_6_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_6_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 6 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 6 Predictions </div> <h3 id="model-7">Model 7</h3> <p>Combines SCSE attention, weighted focal loss, Dice loss, AdamW optimizer, and a cosine annealing scheduler with warm restarts for refined performance.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_7_training-480.webp 480w,/assets/img/model_7_training-800.webp 800w,/assets/img/model_7_training-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_7_training.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 7 Training" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 7 Training </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_7_prediction_grid-480.webp 480w,/assets/img/model_7_prediction_grid-800.webp 800w,/assets/img/model_7_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_7_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 7 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 7 Predictions </div> <h2 id="model-comparison">Model Comparison</h2> <p>Model 1 achieved the best balance across metrics, consistently leading in Dice, IoU, Precision, and Recall. Model 4 offered computational efficiency with minimal accuracy loss. Model 6’s attention blocks improved performance on challenging classes, while Models 2 and 7 underperformed.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_comparison_1-480.webp 480w,/assets/img/model_comparison_1-800.webp 800w,/assets/img/model_comparison_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_comparison_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Overall Comparison" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Overall Comparison </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_comparison_2-480.webp 480w,/assets/img/model_comparison_2-800.webp 800w,/assets/img/model_comparison_2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_comparison_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Class-Wise IoU Comparison" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Class-Wise IoU Comparison </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_comparision_3-480.webp 480w,/assets/img/model_comparision_3-800.webp 800w,/assets/img/model_comparision_3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_comparision_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Class-Wise Dice Comparison" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Class-Wise Dice Comparison </div> <h2 id="conclusion">Conclusion</h2> <p>This work highlights the strengths and trade-offs of various modifications to the U-Net architecture for aerial image segmentation. Model 1, despite being the most basic, was the highest-performing model across all evaluation metrics. Model 4 demonstrates that computational efficiency can be achieved without substantial loss in accuracy. Model 6 showcases the value of attention mechanisms for complex regions. However, limitations remain in capturing fine boundaries and in class imbalance. A simple improvement may be to use an ensemble of U-Nets <a class="citation" href="#Marmanis2016">(Marmanis et al., 2016)</a>.</p> <h2 id="future-work">Future Work</h2> <p>Future improvements include:</p> <ul> <li>Multi-scale feature extraction (e.g., feature pyramids)</li> <li>Conditional Random Fields for post-processing</li> <li>Advanced encoders (ResNet, Vision Transformers)</li> <li>Exploring other architectures (DeepLabv3+, PSPNet, Mask R-CNN)</li> </ul> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="NASM_AerialPhotography" class="col-sm-8"> <div class="title">The Beginnings and Basics of Aerial Photography</div> <div class="author"> National Air and Space Museum </div> <div class="periodical"> Jul 2023 </div> <div class="periodical"> Accessed: Dec. 8, 2024 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zhang2023dive" class="col-sm-8"> <div class="title">Dive into Deep Learning</div> <div class="author"> Aston Zhang, Zachary C. Lipton, Mu Li, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Alexander J. Smola' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> Jul 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Dabra2023" class="col-sm-8"> <div class="title">Evaluating green cover and open spaces in informal settlements of Mumbai using deep learning</div> <div class="author"> Ayush Dabra and Vaibhav Kumar </div> <div class="periodical"> <em>Neural Computing and Applications</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1007/s00521-023-08320-7" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="tan2020efficientnetrethinkingmodelscaling" class="col-sm-8"> <div class="title">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</div> <div class="author"> Mingxing Tan and Quoc V. Le </div> <div class="periodical"> Jul 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Iakubovskii:2019" class="col-sm-8"> <div class="title">Segmentation Models Pytorch</div> <div class="author"> Pavel Iakubovskii </div> <div class="periodical"> Jul 2019 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="roy2018recalibratingfullyconvolutionalnetworks" class="col-sm-8"> <div class="title">Recalibrating Fully Convolutional Networks with Spatial and Channel ’Squeeze &amp; Excitation’ Blocks</div> <div class="author"> Abhijit Guha Roy, Nassir Navab, and Christian Wachinger </div> <div class="periodical"> Jul 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Marmanis2016" class="col-sm-8"> <div class="title">Semantic Segmentation of Aerial Images with an Ensemble of CNNs</div> <div class="author"> D. Marmanis, J. D. Wegner, S. Galliani, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'K. Schindler, M. Datcu, U. Stilla' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences</em>, Jul 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.5194/isprs-annals-III-3-473-2016" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li></ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ronneberger2015unetconvolutionalnetworksbiomedical" class="col-sm-8"> <div class="title">U-Net: Convolutional Networks for Biomedical Image Segmentation</div> <div class="author"> Olaf Ronneberger, Philipp Fischer, and Thomas Brox </div> <div class="periodical"> Jul 2015 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Baumann_RemoteSensingHistory" class="col-sm-8"> <div class="title">HISTORY OF REMOTE SENSING, AERIAL PHOTOGRAPHY</div> <div class="author"> P. Baumann </div> <div class="periodical"> Jul 2014 </div> <div class="periodical"> Accessed: Dec. 8, 2024 </div> <div class="links"> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Grayson M. Martin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>
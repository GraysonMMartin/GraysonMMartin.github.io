<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Semantic Segmentation of Aerial Photographs | Grayson M. Martin </title> <meta name="author" content="Grayson M. Martin"> <meta name="description" content="Per-pixel land use classification of sattelite imagery of Mumbai"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://graysonmmartin.github.io/projects/cs2831_project/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Grayson</span> M. Martin </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Semantic Segmentation of Aerial Photographs</h1> <p class="post-description">Per-pixel land use classification of sattelite imagery of Mumbai</p> </header> <article> <h2 id="abstract">Abstract</h2> <p>Semantic segmentation of aerial imagery is a critical tool for applications such as environmental monitoring, urban planning, and disaster assessment. In this project, I employed the U‑Net architecture with various enhancements—loss function modifications, encoder depth adjustments, dropout regularization, and attention mechanisms—to improve segmentation accuracy on satellite images of Mumbai. Seven models were trained and evaluated using IoU, Dice, Precision, and Recall across six classes (vegetation, built‑up areas, informal settlements, impervious surfaces, barren land, and water) plus a small “unclassified” class.</p> <h2 id="introduction">Introduction</h2> <p>Aerial photography has a wide variety of uses, including geology, archaeology, disaster assessment, and environmental monitoring. Semantic segmentation, or pixel‑wise classification, enables the creation of masks that classify every region of an aerial image, supporting monitoring of environmental conditions, foreign objects, and temporal changes.</p> <h3 id="semantic-segmentation-performance-metrics">Semantic Segmentation Performance Metrics</h3> <p>Performance metrics are defined in terms of true positive (TP), false positive (FP), false negative (FN), and true negative (TN) pixels. The most common metric is the Jaccard Score (IoU):</p> \[\mathrm{IoU} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP} + \mathrm{FN}}\] <p>Precision and Recall are:</p> \[\mathrm{Precision} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}},\quad \mathrm{Recall} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}\] <p>The F1 Score (Dice) is the harmonic mean:</p> \[\mathrm{F1} = 2 \times \frac{\mathrm{Precision} \times \mathrm{Recall}}{\mathrm{Precision} + \mathrm{Recall}}\] <h3 id="transposed-convolution">Transposed Convolution</h3> <p>Transposed convolution (upconvolution) upsamples by inserting zeros between pixels before convolving:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/didl_transposed_convolution-480.webp 480w,/assets/img/didl_transposed_convolution-800.webp 800w,/assets/img/didl_transposed_convolution-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/didl_transposed_convolution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="An Example Upconvolution with a 2×2 Input, 2×2 Kernel, and Stride of 1" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> An Example Upconvolution with a 2×2 Input, 2×2 Kernel, and Stride of 1 </div> <h2 id="dataset-description">Dataset Description</h2> <p>The dataset is the Manually Annotated High Resolution Satellite Image Dataset of Mumbai <a href="https://doi.org/10.17632/xj2v49zt26.1" rel="external nofollow noopener" target="_blank">DOI</a>. It contains 110 images (600×600) split into overlapping 120×120 patches. Classes: vegetation, built‑up areas, informal settlements, impervious surfaces, barren land, water, plus unclassified.</p> <table> <thead> <tr> <th>Class</th> <th style="text-align: right">Informal Settlements</th> <th style="text-align: right">Built‑Up</th> <th style="text-align: right">Impervious Surfaces</th> <th style="text-align: right">Vegetation</th> <th style="text-align: right">Barren</th> <th style="text-align: right">Water</th> <th style="text-align: right">Unclassified</th> </tr> </thead> <tbody> <tr> <td><strong># pixels</strong></td> <td style="text-align: right">12,921,604</td> <td style="text-align: right">11,358,632</td> <td style="text-align: right">13,436,578</td> <td style="text-align: right">22,423,411</td> <td style="text-align: right">18,735,038</td> <td style="text-align: right">37,789,523</td> <td style="text-align: right">120,366</td> </tr> </tbody> </table> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Dabra_class_balance-480.webp 480w,/assets/img/Dabra_class_balance-800.webp 800w,/assets/img/Dabra_class_balance-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Dabra_class_balance.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Distribution of Labels Across Patches" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Distribution of Labels Across Patches </div> <h2 id="methods">Methods</h2> <h3 id="unet-architecture">U‑Net Architecture</h3> <p>The original U‑Net has a contracting encoder and expanding decoder with skip connections:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Ronneberger_architecture-480.webp 480w,/assets/img/Ronneberger_architecture-800.webp 800w,/assets/img/Ronneberger_architecture-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Ronneberger_architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="The Original U‑Net Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The Original U‑Net Architecture </div> <h3 id="loss-functions">Loss Functions</h3> <h4 id="crossentropy">Cross‑Entropy</h4> \[\mathcal{L}_{ce} = -\sum_{(x,y)} y(x,y)\,\log p(x,y)\] <h4 id="weighted-crossentropy">Weighted Cross‑Entropy</h4> \[\mathcal{L}_{wce} = -\sum_{(x,y)} w(x,y)\;y(x,y)\,\log p(x,y)\] <h4 id="focal-loss">Focal Loss</h4> \[\mathcal{L}_{wfl} = -\sum_{(x,y)}\sum_{c=1}^K w_c\,(1 - p_c(x,y))^\gamma\;y_c(x,y)\,\log p_c(x,y)\] <h3 id="data-augmentation">Data Augmentation</h3> <p>Patches are upsampled to 128×128 (a multiple of 32 for the five down‑sampling stages). Random 90° rotations per epoch add rotational invariance.</p> <h3 id="model-selection">Model Selection</h3> <p>Used the Segmentation Models PyTorch library with an EfficientNet‑B0 encoder (4M parameters).</p> <h3 id="optimizer--scheduler">Optimizer &amp; Scheduler</h3> <p>Adam optimizer with initial learning rate (1\times10^{-4}); LambdaLR scheduler:</p> \[\lambda(\mathrm{epoch}) = 0.1^{\frac{\mathrm{epoch}}{40}}\] <h3 id="early-stopping">Early Stopping</h3> <p>Training halts if validation loss doesn’t improve for 5 epochs.</p> <h2 id="results">Results</h2> <h3 id="model1">Model 1</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_1_training-480.webp 480w,/assets/img/model_1_training-800.webp 800w,/assets/img/model_1_training-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_1_training.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 1 Training" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 1 Training </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_1_prediction_grid-480.webp 480w,/assets/img/model_1_prediction_grid-800.webp 800w,/assets/img/model_1_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_1_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 1 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 1 Predictions </div> <h3 id="model2">Model 2</h3> <p>This model introduces Dice loss alongside cross-entropy loss to better address class imbalance by directly optimizing for overlap between predicted and ground truth masks.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_2_prediction_grid-480.webp 480w,/assets/img/model_2_prediction_grid-800.webp 800w,/assets/img/model_2_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_2_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 2 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 2 Predictions </div> <h3 id="model3">Model 3</h3> <p>To further handle class imbalance, class-weighted cross-entropy is combined with Dice loss. Weights were computed based on inverse class frequency and normalized.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_3_prediction_grid-480.webp 480w,/assets/img/model_3_prediction_grid-800.webp 800w,/assets/img/model_3_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_3_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 3 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 3 Predictions </div> <h3 id="model4">Model 4</h3> <p>This model uses a shallower U‑Net (encoder depth 4) with decoder channels [256,128,64,32] to reduce computational overhead while maintaining performance.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_4_prediction_grid-480.webp 480w,/assets/img/model_4_prediction_grid-800.webp 800w,/assets/img/model_4_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_4_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 4 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 4 Predictions </div> <h3 id="model5">Model 5</h3> <p>Dropout regularization (p=0.2) is added to the decoder to improve generalization and reduce overfitting on noisy data.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_5_prediction_grid-480.webp 480w,/assets/img/model_5_prediction_grid-800.webp 800w,/assets/img/model_5_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_5_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 5 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 5 Predictions </div> <h3 id="model6">Model 6</h3> <p>Spatial and Channel Squeeze-and-Excitation (SCSE) blocks are incorporated in the decoder to recalibrate feature channels and improve focus on important regions.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_6_prediction_grid-480.webp 480w,/assets/img/model_6_prediction_grid-800.webp 800w,/assets/img/model_6_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_6_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 6 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 6 Predictions </div> <h3 id="model7">Model 7</h3> <p>Combines SCSE attention, weighted focal loss, Dice loss, AdamW optimizer, and a cosine annealing scheduler with warm restarts for the most refined performance.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_7_training-480.webp 480w,/assets/img/model_7_training-800.webp 800w,/assets/img/model_7_training-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_7_training.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 7 Training" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 7 Training </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model_7_prediction_grid-480.webp 480w,/assets/img/model_7_prediction_grid-800.webp 800w,/assets/img/model_7_prediction_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model_7_prediction_grid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Model 7 Predictions" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Model 7 Predictions </div> <h2 id="conclusion">Conclusion</h2> <p>Model 1 achieved the best balance across metrics. Model 4 offered computational efficiency with minimal accuracy loss. Model 6’s attention blocks improved performance on challenging classes. Future work includes multi‑scale feature extraction, CRF post‑processing, advanced encoders (ResNet, ViT), and exploring newer architectures (DeepLabv3+, PSPNet, Mask R‑CNN).</p> <h2 id="references">References</h2> <p>[1] National Air and Space Museum, “The Beginnings and Basics of Aerial Photography,” Available: https://airandspace.si.edu/stories/editorial/beginnings-and-basics-aerial-photography. Accessed: Dec. 8, 2024.</p> <p>[2] P. Baumann, “HISTORY OF REMOTE SENSING, AERIAL PHOTOGRAPHY,” Available: http://employees.oneonta.edu/baumanpr/geosat2/rs%20history%20i/rs-history-part-1.htm. Accessed: Dec. 8, 2024.</p> <p>[3] A. Dabra, “Manually Annotated High Resolution Satellite Image Dataset of Mumbai for Semantic Segmentation,” Mendeley, 2023. Available: https://data.mendeley.com/datasets/xj2v49zt26/1.</p> <p>[4] G. Csurka, R. Volpi, B. Chidlovskii, “Semantic Image Segmentation: Two Decades of Research,” arXiv:2302.06378, 2023.</p> <p>[5] O. Ronneberger, P. Fischer, T. Brox, “U-Net: Convolutional Networks for Biomedical Image Segmentation,” arXiv:1505.04597, 2015.</p> <p>[6] P. Iakubovskii, “Segmentation Models Pytorch,” GitHub repository, 2019. Available: https://github.com/qubvel/segmentation_models.pytorch.</p> <p>[7] A. Dabra, V. Kumar, “Evaluating Green Cover and Open Spaces in Informal Settlements of Mumbai Using Deep Learning,” Neural Computing and Applications, 2023. DOI: 10.1007/s00521-023-08320-7.</p> <p>[8] A. Zhang, Z. C. Lipton, M. Li, A. J. Smola, “Dive into Deep Learning,” Cambridge University Press, 2023. Available: https://d2l.ai.</p> <p>[9] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, F.-F. Li, “ImageNet: A Large-Scale Hierarchical Image Database,” in Proc. IEEE CVPR, 2009, pp. 248–255. DOI: 10.1109/CVPR.2009.5206848.</p> <p>[10] M. Tan, Q. V. Le, “EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,” arXiv:1905.11946, 2020.</p> <p>[11] A. G. Roy, N. Navab, C. Wachinger, “Recalibrating Fully Convolutional Networks with Spatial and Channel ‘Squeeze &amp; Excitation’ Blocks,” arXiv:1808.08127, 2018.</p> <p>[12] D. Marmanis, J. D. Wegner, S. Galliani, K. Schindler, M. Datcu, U. Stilla, “Semantic Segmentation of Aerial Images with an Ensemble of CNNs,” ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences, vol. III-3, pp. 473–480, 2016. DOI: 10.5194/isprs-annals-III-3-473-2016.</p> </article> <h2>References</h2> <div class="publications"> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Grayson M. Martin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>